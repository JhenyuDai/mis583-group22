# é‚£é‚Šæœ‰ä¸€éš»è¶…å¯æ„›çš„ç‹—å‹¾ï¼ç‹—ç‹—åˆ†é¡å¤§æŒ‘æˆ°ï¼
## Fine-Grained Visual Classification: Dog Breed Identification

**Kaggle : 2025 Iyatomi Lab. Competition â€”â€” 2025 Iyatomi å¯¦é©—å®¤èª²å ‚å½±åƒåˆ†é¡ç«¶è³½**
ğŸ”— [ç«¶è³½é é¢ç¸½è¦½ (Overview)](https://www.kaggle.com/competitions/2025-iyatomi-lab-competition/overview)

![Python](https://img.shields.io/badge/Python-3.11-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red)
![Rank](https://img.shields.io/badge/Kaggle_Rank-2nd_Place-gold)
![Accuracy](https://img.shields.io/badge/Best_Valid_Acc-92.48%25-green)

---

## å°ˆæ¡ˆæ¦‚è¿°

æœ¬å°ˆæ¡ˆæ—¨åœ¨è§£æ±º **ç´°ç²’åº¦è¦–è¦ºåˆ†é¡ (Fine-Grained Visual Classification, FGVC)** çš„æŒ‘æˆ°ï¼Œç›®æ¨™æ˜¯æº–ç¢ºå€åˆ† 120 ç¨®å¤–è§€é«˜åº¦ç›¸ä¼¼çš„çŠ¬ç¨®ï¼ˆä¾‹å¦‚ï¼šè¥¿ä¼¯åˆ©äºå“ˆå£«å¥‡èˆ‡é˜¿æ‹‰æ–¯åŠ é›ªæ©‡çŠ¬ï¼‰ï¼Œä¸åŒæ–¼ä¸€èˆ¬çš„è²“ç‹—åˆ†é¡ï¼Œæ­¤ä»»å‹™è¦æ±‚æ¨¡å‹å…·å‚™æ¥µå¼·çš„å±€éƒ¨ç‰¹å¾µæå–èƒ½åŠ›ï¼Œä»¥è¾¨è­˜çœ¼ç›å½¢ç‹€ã€æ¯›è‰²ç´‹ç†èˆ‡å£é¼»é•·åº¦ç­‰ç´°å¾®å·®ç•°ã€‚

é€™é …å°ˆæ¡ˆæ˜¯ç‚ºäº† **2025 Iyatomi Lab Competition** æ‰€é–‹ç™¼ï¼Œæœ€çµ‚åœ¨ Kaggle Private Leaderboard å–å¾— **0.86177**ï¼Œæ¦®ç²ç¬¬äºŒåçš„æˆç¸¾ã€‚

---

## æ ¸å¿ƒæˆæ•ˆèˆ‡å¯¦é©—çµæœ

æˆ‘å€‘æ¯”è¼ƒäº†å¾è¼•é‡ç´š CNN åˆ° Transformer çš„å¤šç¨®æ¶æ§‹ï¼Œå¯¦é©—è­‰æ˜ **Vision Transformer (ViT)** åœ¨æ­¤ä»»å‹™ä¸Šè¡¨ç¾æœ€ä½³ã€‚

| æ¨¡å‹æ¶æ§‹ (Model) | å„ªåŒ–ç­–ç•¥ (Strategy) | æœ€ä½³é©—è­‰æº–ç¢ºç‡ (Best Val Acc) | Kaggle Private LB |
| :--- | :--- | :--- | :--- |
| **ViT-b-16** | **é è¨“ç·´ + æ¨™ç±¤å¹³æ»‘ (Label Smoothing)** | **92.48%** | **0.86177** |
| ResNet-50 | CBAM (æ³¨æ„åŠ›æ©Ÿåˆ¶) + è§£å‡è¨“ç·´ | 88.72% | - |
| EfficientNet-b4 | æ¨™ç±¤å¹³æ»‘ (Label Smoothing) | 87.21% | - |
| EfficientNet-b3 | CBAM (æ³¨æ„åŠ›æ©Ÿåˆ¶) | 87.00% | - |

---

## æ–¹æ³•è«–èˆ‡ç­–ç•¥

### 1. æ¨¡å‹æ¶æ§‹å‰µæ–° (Architecture Optimization)
* **CNN æ”¹è‰¯ (CNN + CBAM):** é‡å° ResNet èˆ‡ EfficientNet ç³»åˆ—ï¼Œæˆ‘å€‘æ‰‹å‹•åµŒå…¥äº† **CBAM (Convolutional Block Attention Module)** æ³¨æ„åŠ›æ¨¡çµ„ã€‚é€™å¼·åˆ¶æ¨¡å‹å»é—œæ³¨ã€Œå“ªå€‹ç‰¹å¾µé€šé“é‡è¦ (Channel Attention)ã€ä»¥åŠã€Œå“ªå€‹åœ–ç‰‡ä½ç½®é‡è¦ (Spatial Attention)ã€ï¼ŒæˆåŠŸå°‡ ResNet-50 çš„æº–ç¢ºåº¦å¾ 81.95% å¤§å¹…æå‡è‡³ 88.72%ã€‚
* **Transformer æ‡‰ç”¨:** æ¡ç”¨ `vit_b_16` é€²è¡Œé·ç§»å­¸ç¿’ï¼Œå°‡åœ–åƒåˆ†å‰²ç‚º $16 \times 16$ çš„ Patchï¼Œåˆ©ç”¨ Transformer Encoder è™•ç†é•·è·é›¢çš„ç‰¹å¾µä¾è³´ã€‚

### 2. è¨“ç·´ç­–ç•¥ (Training Strategy)
ç‚ºäº†å…‹æœè³‡æ–™é›†è¼ƒå° (ç´„ 1200 å¼µ) å¸¶ä¾†çš„éæ“¬åˆé¢¨éšªï¼Œæˆ‘å€‘å¯¦æ–½äº†åš´æ ¼çš„è¨“ç·´æµç¨‹ï¼š
* **æ¼¸é€²å¼è§£å‡ (Progressive Unfreezing):** åˆæœŸå‡çµéª¨å¹¹ç¶²è·¯ (Backbone)ï¼Œåƒ…è¨“ç·´åˆ†é¡é ­ (Classifier)ã€‚
* **åˆ†çµ„å­¸ç¿’ç‡ (Differential Learning Rates):**
    * Backbone (é è¨“ç·´å±¤): $1 \times 10^{-5}$ (ä¿ç•™é€šç”¨ç‰¹å¾µ)
    * Classifier (æ–°å±¤): $1 \times 10^{-3}$ (å¿«é€Ÿé©æ‡‰æ–°é¡åˆ¥)
* **å„ªåŒ–å™¨è¨­å®š:** ä½¿ç”¨ `RAdam` æ­é… `CosineAnnealingLR` æ’ç¨‹å™¨ï¼Œå¯¦ç¾ç©©å®šçš„æ”¶æ–‚ã€‚

### 3. è³‡æ–™å¢å¼·åˆ†æ (Data Augmentation Analysis)
* **æœ‰æ•ˆç­–ç•¥:** éš¨æ©Ÿè£åˆ‡ (Random Resized Crop)ã€æ°´å¹³ç¿»è½‰ (Horizontal Flip)ã€æ­£è¦åŒ– (Normalization)ã€‚
* **ç„¡æ•ˆ/è² é¢ç­–ç•¥:** å¯¦é©—ç™¼ç¾ **AutoAugment** èˆ‡ **TTA (Test Time Augmentation)** åè€Œå°è‡´æº–ç¢ºåº¦ä¸‹é™ï¼ˆä¾‹å¦‚ EfficientNet-b1 ä¸‹é™è‡³ 0.83ï¼‰ã€‚æ¨æ¸¬æ˜¯å› ç‚ºåœ¨å°è¦æ¨¡æ•¸æ“šé›†ä¸Šï¼Œéåº¦æ¿€é€²çš„å¹¾ä½•è®Šæ›ç ´å£äº†å€åˆ†å“ç¨®çš„é—œéµç´°å¾®ç‰¹å¾µã€‚

---

## å¯è§£é‡‹æ€§åˆ†æ (Explainability)

åˆ©ç”¨ **Grad-CAM** æŠ€è¡“ï¼Œæˆ‘å€‘è¦–è¦ºåŒ–äº†æ¨¡å‹çš„é—œæ³¨å€åŸŸï¼Œä»¥é©—è­‰æ¨¡å‹æ˜¯å¦å­¸åˆ°äº†æ­£ç¢ºçš„ç‰¹å¾µã€‚

| æˆåŠŸæ¡ˆä¾‹ (Success) | å¤±æ•—/å¤šç›®æ¨™æ¡ˆä¾‹ (Failure) |
| :---: | :---: |
| <img src="https://github.com/user-attachments/assets/da2c6af8-0e62-4ec4-a968-76fac1b5a148" width="300"> | <img src="https://github.com/user-attachments/assets/437d525e-2c5b-4b72-a430-b89d7a7243f4" width="300"> |
| **åˆ†æ:** æ¨¡å‹æº–ç¢ºåœ°å°‡æ³¨æ„åŠ›é›†ä¸­åœ¨çŠ¬éš»çš„**é ­éƒ¨èˆ‡äº”å®˜**ï¼Œé€™æ˜¯å€åˆ†å“ç¨®çš„æœ€é—œéµå€åŸŸ ã€‚ | **åˆ†æ:** ç•¶ç•«é¢ä¸­æœ‰å¤šéš»ç‹—æˆ–èƒŒæ™¯è¤‡é›œæ™‚ï¼Œæ¨¡å‹çš„æ³¨æ„åŠ›æœ‰æ™‚æœƒåˆ†æ•£ï¼Œç”šè‡³éŒ¯èª¤é—œæ³¨åˆ°èƒŒæ™¯è‰åœ°ï¼Œå°è‡´é æ¸¬ä¿¡å¿ƒä¸‹é™ã€‚ |

---

## å¦‚ä½•åŸ·è¡Œ (How to Run)

æœ¬å°ˆæ¡ˆçš„æ‰€æœ‰å¯¦ä½œé‚è¼¯å‡æ•´åˆæ–¼ Jupyter Notebook ä¸­ã€‚

1.  **ç’°å¢ƒéœ€æ±‚ (Requirements):**
    ```bash
    pip install torch torchvision grad-cam pandas opencv-python matplotlib
    ```

2.  **åŸ·è¡Œè¨“ç·´:**
    é–‹å•Ÿ `mis583_group22.ipynb`ï¼Œè©² Notebook åŒ…å«å®Œæ•´çš„ End-to-End æµç¨‹ï¼š
    * **è³‡æ–™é è™•ç†:** å®šç¾© Transform èˆ‡ DataLoaderã€‚
    * **æ¨¡å‹å»ºæ§‹:** åŒ…å« `get_base_model()` èˆ‡è‡ªå®šç¾©çš„ `CNNWithCBAM` é¡åˆ¥ã€‚
    * **è¨“ç·´è¿´åœˆ:** åŒ…å« RAdam å„ªåŒ–å™¨èˆ‡é©—è­‰æ©Ÿåˆ¶ã€‚
    * **è¦–è¦ºåŒ–:** åŸ·è¡Œ Grad-CAM ç¨‹å¼ç¢¼å€å¡Šä»¥ç”Ÿæˆç†±åŠ›åœ–ã€‚

---

## åœ˜éšŠæˆå“¡ (Contributors)

**åœ‹ç«‹ä¸­å±±å¤§å­¸ è³‡è¨Šç®¡ç†å­¸ç³»ç¢©å£«ç­**
**Department of Information Management, National Sun Yat-sen University**

* **M144020035 é™³å½¥å®‡** 
* **M144020054 æˆ´æŒ¯å®‡** 
* **M144020056 å¼µç¥è±ª** 

---

## åƒè€ƒæ–‡ç» (References)
1.  Kaggle Competition: [2025 Iyatomi Lab. Competition](https://www.kaggle.com/competitions/2025-iyatomi-lab-competition/overview)
2.  Dosovitskiy, A., et al. "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale." ICLR 2021.
3.  Woo, S., et al. "CBAM: Convolutional Block Attention Module." ECCV 2018.
4.  Selvaraju, R. R., et al. "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization." ICCV 2017.
